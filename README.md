# 🧪 MixUp_팀명 : Grammar Error Correction Promptathon 

본 레포지토리는 Grammar Error Correction Promptathon  실험을 재현하고 확장하기 위한 코드 및 가이드를 제공합니다.


## 프로젝트 개요

* **목표**: Solar Pro API를 활용하고 다양한 고급 프롬프팅 기법(Role & Expert Prompting, Step-by-step, Tree-of-Thought, Few-shot & Chat Prompting, Automated Prompt Engineering, TF-IDF few-shot retrieval 등)을 적용하여 한국어 맞춤법 교정 성능을 극대화한다.
* **접근 전략**:
    * **EDA (Exploratory Data Analysis)**: 데이터 분석을 통해 오류 유형 및 패턴을 파악하고, 이를 바탕으로 프롬프트의 단계적 구성을 정하고 규칙을 수립한다. 모델이 시스템 프롬프트 없이 오류를 찾는 과정을 분석하여, 모델의 오류 탐지 및 수정 근거를 파악하고 Step-by-step Prompting에 빈도수대로 반영한다.
    * **Role & Expert Prompting**: 모델에게 특정 역할(예: 맞춤법 교정 전문가)을 부여하여 해당 역할에 맞는 전문적인 답변을 유도한다.
    * **Step-by-step Prompting**: 모델이 복잡한 문제를 해결하기 위해 단계별로 사고하도록 유도하여 추론 과정을 돕고 정확도를 향상시킨다. (예: 오류 분석 -> 수정 방향 제시 -> 교정)
    * **Tree-of-Thought (ToT) Prompting**: 단일 API 호출 내에서 여러 추론 경로를 탐색하고 결합하여, 더 정교하고 신뢰성 높은 교정 결과를 도출한다.
    * **Few-shot Prompting & Chat Prompting (Multi-Turn)**: 소수의 예시(Few-shot)를 제공하고, 멀티턴 대화 형식을 활용하여 모델이 수행해야 할 작업과 추론 방식을 명확하게 이해하도록 돕는다.
    * **Automated Prompt Engineering**: 대규모 언어 모델(LLM)과의 지속적인 상호작용을 통해 프롬프트를 주기적으로 평가하고 개선하여 최적의 프롬프트를 탐색한다.
    * **TF-IDF Few-shot Retrieval**: TF-IDF를 사용하여 입력 문장과 가장 유사한 오류 및 교정 예시를 동적으로 선택하여 Few-shot 프롬프트에 포함함으로써, 문맥에 맞는 효과적인 예시를 제공한다.
    * **프롬프트 규칙 및 내용**:
        * 데이터 분석을 통해 도출된 주요 오류 유형 및 수정 패턴을 기반으로 프롬프트 규칙을 설계한다.
        * 각 프롬프팅 기법의 특성을 고려하여 규칙과 내용을 최적화한다.

* **주요 실험 내용**:
    * 위에 언급된 다양한 프롬프팅 전략들을 조합하고 실험하여 각 기법의 효과와 최적의 조합을 탐색한다.
    * **성공적인 접근법**:
        * EDA 결과를 바탕으로 Step-by-step 프롬프트의 단계를 구체화하고, 각 단계에서 모델이 집중해야 할 오류 유형을 명시.
        * Tree-of-Thought를 적용하여 여러 교정 후보를 생성하고, 그중 가장 문맥적으로 적절하며 원문과 발음이 유사한 결과를 선택하도록 유도.
        * TF-IDF를 활용한 Few-shot 예시 선택으로 일반적인 Few-shot 방식보다 문맥 유사성이 높은 예시를 제공하여 성능 향상.
    * **시도했으나 효과가 미미했던 방식**:
        * **Chain-of-Thought (CoT)**: 모델이 명시적으로 맞춤법 오류를 지정하고 사고 과정을 설명하도록 유도했으나, 복잡한 오류나 미묘한 문맥에서는 정확한 사고 과정을 생성하지 못하는 경우가 많았다.
        * **Multi-Agent**: 여러 에이전트(API 호출)를 사용하여 각기 다른 측면(예: 오타, 띄어쓰기, 문법)을 점검하도록 구성했으나, API 호출 횟수 증가 대비 성능 향상이 미미했고, 각 호출 시 토큰 제한으로 인해 충분한 Few-shot 예시나 상세한 시스템 프롬프트를 전달하기 어려웠다.
---

## ⚙️ 환경 세팅 & 실행 방법

### 1. 사전 준비 

```bash
git clone https://github.com/your-org/your-repo.git # 실제 레포지토리 주소로 변경해주세요.
cd your-repo # 실제 레포지토리 명으로 변경해주세요.
```

### 라이브러리 설치

```bash
pip install -r requirements.txt
```

### 실험 실행

```bash
python main.py # main.py 실행으로 변경 (기존 run_experiment.py에서)
```

> 📎 실행 옵션:
> 스크립트 내 `config.py` 또는 직접 코드 수정을 통해 실험 옵션 조절 가능 (예: `toy_size`, `template_name` 등)

---


## 🚧 실험의 한계 및 향후 개선

* **한계**:
  * **문장 부호 오류 교정의 미흡**: 특히 쉼표(,)와 같은 특정 문장 부호의 사용을 정확하게 교정하는 데 어려움이 있습니다.
  * **Ablation Study 부족**: Few-shot 예시의 수와 일반화를 위한 랜덤 샘플링 개수 등 하이퍼파라미터 변화에 따른 성능 비교 분석(Ablation Study)이 충분히 이루어지지 못했습니다.
  * **API 호출 제한 활용 미흡**: 제공된 API 호출 횟수(예: 3회)를 전략적으로 모두 활용하여 성능을 극대화하는 방안을 충분히 탐색하지 못했습니다. (예: 첫 번째 호출에서 초벌 교정, 두 번째 호출에서 세부 오류 검토, 세 번째 호출에서 최종 검증 등)
  * **복잡하거나 미묘한 오류 처리**: 신조어, 전문 용어, 다의어 해석이 필요한 문맥, 또는 매우 미묘한 문법적 오류에 대해서는 여전히 교정 성능이 부족할 수 있습니다.

* **향후 개선 방향**:
  * **문장 부호 교정 강화**: 문장 부호 사용 규칙에 대한 명시적인 지침을 프롬프트에 추가하거나, 문장 부호 교정에 특화된 후처리 로직을 개발합니다.
  * **체계적인 Ablation Study 수행**: Few-shot 예시의 구성 방식, 개수, 랜덤 샘플링 전략 등 다양한 하이퍼파라미터에 대한 실험을 체계적으로 수행하여 최적의 조합을 찾습니다.
  * **API 호출 최적화 전략 연구**: 제한된 API 호출 횟수 내에서 각 호출의 역할을 명확히 정의하고, 다단계 교정 프로세스(예: Coarse-to-fine)를 설계하여 호출 효율성을 극대화합니다. 예를 들어, 첫 호출은 전체적인 문맥과 주요 오류를 교정하고, 다음 호출은 특정 오류 유형(문장 부호, 띄어쓰기 등)에 집중하는 방식을 고려할 수 있습니다.
  * **Self-Critique 및 Refinement Loop 도입**: 모델이 스스로 생성한 교정안을 평가하고, 문제점을 발견하면 다시 교정을 시도하는 반복적인 개선 루프를 프롬프트에 설계하여 교정의 완성도를 높입니다.

---

## 📂 폴더 구조

```
📁 .
├── main.py              # 메인 실행 파일
├── config.py            # 설정 파일
├── requirements.txt     # 필요한 패키지 목록
├── README.md            # 프로젝트 설명 파일
├── data/                # 데이터 저장 (train.csv, test.csv 등)
│   └── ...
├── utils/               # 유틸리티 함수들
│   ├── __init__.py      # utils 패키지 초기화
│   └── experiment.py    # 실험 실행 및 API 호출
└── prompts/             # 프롬프트 템플릿 저장
    ├── __init__.py      # prompts 패키지 초기화
    └── templates.py     # 프롬프트 템플릿 정의
``` 